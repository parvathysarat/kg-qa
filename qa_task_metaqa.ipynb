{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "qa_task_metaqa.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPJdj6iIGi7/drivzHPI0wr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parvathysarat/kg-qa/blob/master/qa_task_metaqa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCRC0sIwYVHZ",
        "colab_type": "text"
      },
      "source": [
        "Size of our transG embeddings : 50 (both entities and relations)\n",
        "\n",
        "(contains : \n",
        "- utility functions to get entities, relations, documents from MetaQA processed files\n",
        "- training functions\n",
        "- embedding functions\n",
        "- main\n",
        "<br> Needs to be split into util, training and main files. Also need to add config file with specifications)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzRsTFNQh-DV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "import os\n",
        "import time, datetime\n",
        "import sys\n",
        "import json\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYox1XsCTpyK",
        "colab_type": "code",
        "outputId": "a79eaa16-68b3-448e-f6cc-0aeaa94cd4ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "!git clone https://github.com/parvathysarat/kg-qa\n",
        "# ./kg-qa/data/transg/ has the embeddings obtained by TransG for MetaQA dataset"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'kg-qa'...\n",
            "remote: Enumerating objects: 46, done.\u001b[K\n",
            "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
            "remote: Compressing objects: 100% (42/42), done.\u001b[K\n",
            "remote: Total 46 (delta 16), reused 16 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (46/46), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZqYMyp9W5jp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('./kg-qa/data/transg/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRVc0yyLgA7O",
        "colab_type": "text"
      },
      "source": [
        "### Loading MetaQA datasets - entities, relations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpBbREXgX8PZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import shutil\n",
        "for file in glob.glob('./kg-qa/data/*.txt'):\n",
        "  shutil.move(file,'./kg-qa/data/transg/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m4GwmKLsASk",
        "colab_type": "code",
        "outputId": "dd0f27fe-7157-4491-f2aa-a3d369f90dac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# entities.txt from MetaQa : list of entities\n",
        "\n",
        "def get_entities_relns():\n",
        "  with open('../MetaQA/entities.txt') as f:\n",
        "    entities = {id:line.strip() for id,line in enumerate(f)}\n",
        "    print(len(entities),entities[0])\n",
        "  with open('../MetaQA/relations.txt') as f:\n",
        "    relations = {id:line.strip() for id,line in enumerate(f)}\n",
        "    print(len(relations),relations[0])\n",
        "    return entities, relations    \n",
        "  \n",
        "entities, relations = get_entities_relns()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "43234 Kismet\n",
            "9 has_imdb_rating\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYsP6TcKgHlg",
        "colab_type": "text"
      },
      "source": [
        "### Loading pretrained entity weights (transG) for MetaQA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAp61DouYBYK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# entity.txt storing TransG embeddings of MetaQA\n",
        "\n",
        "def get_num_entity(param='num'):\n",
        "   with open('entity.txt') as f:\n",
        "    if param=='num':\n",
        "      return sum([1 for line in f])\n",
        "    if param=='weights':\n",
        "      arr = []\n",
        "      weights_dict = {}\n",
        "      ct=0\n",
        "      for line in f:\n",
        "        entity = entities[ct]\n",
        "        ct+=1\n",
        "        for idx,el in enumerate(line.split()):\n",
        "          # numeric entities are not vectorized\n",
        "          if el.isnumeric() and idx==0: \n",
        "            continue\n",
        "\n",
        "          if (' '.join(line.split()[:idx]))==entity:\n",
        "            arr.append(np.array(line.split()[idx:],dtype=np.float32))\n",
        "            weights_dict[entity] = np.array(line.split()[idx:],dtype=np.float32)\n",
        "            break\n",
        "      print(len(weights_dict),ct)\n",
        "    pretrained_weights = torch.FloatTensor(arr)  \n",
        "    return weights_dict, pretrained_weights\n",
        "num_entities = get_num_entity()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8sFJIZ5gQAU",
        "colab_type": "code",
        "outputId": "4e9bc67b-661b-4799-8777-55d23c364733",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "num_entities = get_num_entity()\n",
        "entity_weights_dict, pretrained_entity_weights = get_num_entity('weights')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "43233 43234\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNbDy-XYgPfP",
        "colab_type": "text"
      },
      "source": [
        "###Store pretrained weights to embedding vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Opl7WYWljrIJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_embeddings(pretrained_weights):\n",
        "  embeddings = nn.Embedding.from_pretrained(pretrained_weights)  \n",
        "  # entity_embeddings = nn.Embedding(num_embeddings=num_entities+1, embedding_dim=50,padding_idx=num_entities)\n",
        "  # entity_embeddings.weight = nn.Parameter(get_num_entity('weights'))\n",
        "  embeddings.weight.requires_grad = False  \n",
        "  return embeddings\n",
        "entity_embeddings = initialize_embeddings(pretrained_entity_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r83DPFNQyl1h",
        "colab_type": "code",
        "outputId": "a8f0a32b-4a3b-46e5-bc86-87e142368a6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "entity_embeddings"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(43233, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fNDG3FXggkK",
        "colab_type": "text"
      },
      "source": [
        "### Loading pretrained relation weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llPzkMmuzRib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to return the cluster number for each relation\n",
        "# (n_cluster # of embeddings for each relation from TransG based on GMM)\n",
        "\n",
        "def get_relations_clust():\n",
        "  relations_cluster = {}\n",
        "  with open('weight.txt') as f:\n",
        "    for line in f:\n",
        "      relations_cluster[line.split()[0]] = np.argmax(np.array(line.split()[1:], dtype = np.float32))\n",
        "  return relations_cluster\n",
        "rel_clusters = get_relations_clust()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkXFDoFsg2jm",
        "colab_type": "text"
      },
      "source": [
        "(transG uses GMM model hence relations have a mixture of embedding vectors to represent multiple semantic relations, weights of each mixture/cluster stored in weights.txt, loaded into rel_clusters. Here we have used num_clusters=4)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mo4VAGAZDYi8",
        "colab_type": "code",
        "outputId": "460e59b9-b39b-4c2b-84f7-e7a77457ffac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "rel_clusters"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'directed_by': 2,\n",
              " 'has_genre': 3,\n",
              " 'has_imdb_rating': 3,\n",
              " 'has_imdb_votes': 3,\n",
              " 'has_tags': 3,\n",
              " 'in_language': 2,\n",
              " 'release_year': 3,\n",
              " 'starred_actors': 2,\n",
              " 'written_by': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptgBoI6_Dma1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_rel_embeddings(relation):\n",
        "  with open('relation_'+relation+'.txt') as f:\n",
        "    for line in f:\n",
        "      if int(line[0])==rel_clusters[relation]:\n",
        "        return np.array(line.split()[1:],dtype=np.float32)\n",
        "\n",
        "rel_weights_dict= {}\n",
        "pretrained_relation_weights = []\n",
        "for rel in rel_clusters:\n",
        "  rel_weights_dict[rel] = get_rel_embeddings(rel)\n",
        "  pretrained_relation_weights.append(rel_weights_dict[rel])\n",
        "pretrained_relation_weights = torch.FloatTensor(pretrained_relation_weights)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCuKACBJI5rY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "relation_embeddings = initialize_embeddings(pretrained_relation_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GeKANMVJGIX",
        "colab_type": "code",
        "outputId": "38bbfb54-eff7-423a-9918-fee470c98f88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(entity_embeddings,relation_embeddings)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Embedding(43233, 50) Embedding(9, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISXlyIFAllLb",
        "colab_type": "text"
      },
      "source": [
        "Mapping vocabulary, entities and relations to ids. \n",
        "dicts of {value:id} format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFFydLsjKW2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def map_ids(file):\n",
        "  id_map = {}\n",
        "  with open('../MetaQA/'+file+'.txt') as f:\n",
        "    for line in f:\n",
        "      id_map[line.strip()] = len(id_map)\n",
        "  return id_map\n",
        "\n",
        "vocab_ids = map_ids('vocab')\n",
        "relation_ids = map_ids('relations')\n",
        "entity_ids = map_ids('entities')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_04dxdk5iI-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import nltk\n",
        "# nltk.download('punkt')\n",
        "from nltk import word_tokenize\n",
        "from pprint import pprint\n",
        "\n",
        "def map_documents(file):\n",
        "\n",
        "  # first get the json into documents dict\n",
        "\n",
        "  documents = {}\n",
        "  with open(file,encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "      line = json.loads(line)\n",
        "      documents[line['documentId']] = line\n",
        "      documents[line['documentId']]['tokens'] = word_tokenize(line['document']['text'])\n",
        "      if 'title' in line:\n",
        "        documents[line['documentId']]['tokens'] += [\"/\"] + word_tokenize(line['title']['text'])\n",
        "\n",
        "  # index the docs by entities, start, stop etc.\n",
        "  return documents\n",
        "documents = map_documents('../MetaQA/documents.json')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qI0EjyUKntW_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def index_doc_entities(documents):\n",
        "  doc_entity_index = {}\n",
        "  all_doc_texts = {}\n",
        "  all_doc_texts[-1] = np.full(40, len(vocab_ids), dtype=int)\n",
        "  for id, doc in documents.items():\n",
        "    word_ids, entity_ids_global = [],[]\n",
        "    word_weights = []\n",
        "    if 'title' in doc:\n",
        "      for ent in doc['title']['entities'] : \n",
        "        # get number of words (ent['start'] = start word #, ent['end'] = end word #)\n",
        "        len_entity = ent['end'] - ent['start']\n",
        "        # entity id\n",
        "        entity_ids_global.extend([entity_ids[ent['text']]]*len_entity)\n",
        "\n",
        "        word_ids.extend(range(ent['start'],ent['end']))\n",
        "        # word weight = 1/(# of words)\n",
        "        word_weights.extend([1.0/len_entity]*len_entity)\n",
        "      len_title = len(word_tokenize(doc['title']['text']))      \n",
        "    else:\n",
        "      len_title = 0\n",
        "    for ent in doc['document']['entities']:\n",
        "      # capping at 40 tokens\n",
        "      if ent['start'] + len_title+1 >= 40: continue\n",
        "      len_entity = min(40, ent['end']+ len_title+1) - (ent['start']+len_title+1)\n",
        "      entity_ids_global.extend([entity_ids[ent['text']]]*len_entity)\n",
        "      word_ids.extend(range(ent['start']+len_title+1, ent['start']+len_entity+len_title+1))\n",
        "      if len_entity!=0: \n",
        "        word_weights.extend([1.0/len_entity]*len_entity)\n",
        "      \n",
        "    if len(word_weights)!=len(word_ids):\n",
        "      print(len(word_weights),len(word_ids))\n",
        "      raise ValueError(\"Lengths of weights and id's do not match!\") \n",
        "    doc_entity_index[id] = (entity_ids_global,word_ids,word_weights)\n",
        "\n",
        "    each_doc = np.full(40, len(vocab_ids),dtype=int)\n",
        "    for ind, word in enumerate(doc['tokens']):\n",
        "      if ind < 40:\n",
        "        if word in vocab_ids:\n",
        "          each_doc[ind] = vocab_ids[word]\n",
        "        else: each_doc[ind] = vocab_ids['__unk__']\n",
        "\n",
        "    all_doc_texts[id] = each_doc\n",
        "\n",
        "  return doc_entity_index,all_doc_texts\n",
        "\n",
        "# doc_entity_index== ([list of entity ids x #words in entity],[list of entity positions in text],[list of entity weights x #words in entity]\n",
        "doc_entity_index, all_doc_texts = index_doc_entities(documents)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXwPe4Ca-55W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert (len(all_doc_texts.keys())-1) == len(documents)== len(doc_entity_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSu8Eb3gCs1O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7b11c03b-37d8-4682-891a-3be5f9f8f7c2"
      },
      "source": [
        "all_doc_texts[0],documents[0],doc_entity_index[0]"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 1834,    19, 12066, 13413, 11193,  6536,  1460,  2587, 12208,\n",
              "         3064,  7956, 11168, 13493, 12208,  7232,  9018, 11168,  3064,\n",
              "         7956,  3373,  2101,   432,  9018,  4232,   647,  3840,  5928,\n",
              "         1834,  5214,  1460, 11249, 13545, 13545, 13545, 13545, 13545,\n",
              "        13545, 13545, 13545, 13545]),\n",
              " {'document': {'entities': [{'end': 6,\n",
              "     'kb_id': 1721,\n",
              "     'start': 4,\n",
              "     'text': 'romantic comedy'},\n",
              "    {'end': 6, 'kb_id': 4958, 'start': 4, 'text': 'Romantic Comedy'},\n",
              "    {'end': 11, 'kb_id': 12463, 'start': 9, 'text': 'john turturro'},\n",
              "    {'end': 11, 'kb_id': 15468, 'start': 9, 'text': 'John Turturro'},\n",
              "    {'end': 16, 'kb_id': 27467, 'start': 14, 'text': 'Brandon Cole'},\n",
              "    {'end': 1, 'kb_id': 27466, 'start': 0, 'text': 'Illuminata'},\n",
              "    {'end': 4, 'kb_id': 287, 'start': 3, 'text': '1998'},\n",
              "    {'end': 18, 'kb_id': 29534, 'start': 17, 'text': 'john'},\n",
              "    {'end': 25, 'kb_id': 23534, 'start': 24, 'text': 'play'},\n",
              "    {'end': 25, 'kb_id': 25964, 'start': 24, 'text': 'Play'},\n",
              "    {'end': 7, 'kb_id': 728, 'start': 6, 'text': 'film'}],\n",
              "   'text': \"illuminata is a 1998 romantic comedy film directed by john turturro and written by brandon cole and john turturro , based on cole 's play .\"},\n",
              "  'documentId': 0,\n",
              "  'title': {'entities': [{'end': 1,\n",
              "     'kb_id': 27466,\n",
              "     'start': 0,\n",
              "     'text': 'Illuminata'},\n",
              "    {'end': 3, 'kb_id': 728, 'start': 2, 'text': 'film'}],\n",
              "   'text': 'illuminata ( film )'},\n",
              "  'tokens': ['illuminata',\n",
              "   'is',\n",
              "   'a',\n",
              "   '1998',\n",
              "   'romantic',\n",
              "   'comedy',\n",
              "   'film',\n",
              "   'directed',\n",
              "   'by',\n",
              "   'john',\n",
              "   'turturro',\n",
              "   'and',\n",
              "   'written',\n",
              "   'by',\n",
              "   'brandon',\n",
              "   'cole',\n",
              "   'and',\n",
              "   'john',\n",
              "   'turturro',\n",
              "   ',',\n",
              "   'based',\n",
              "   'on',\n",
              "   'cole',\n",
              "   \"'s\",\n",
              "   'play',\n",
              "   '.',\n",
              "   '/',\n",
              "   'illuminata',\n",
              "   '(',\n",
              "   'film',\n",
              "   ')']},\n",
              " ([27466,\n",
              "   728,\n",
              "   1721,\n",
              "   1721,\n",
              "   4958,\n",
              "   4958,\n",
              "   12463,\n",
              "   12463,\n",
              "   15468,\n",
              "   15468,\n",
              "   27467,\n",
              "   27467,\n",
              "   27466,\n",
              "   287,\n",
              "   29534,\n",
              "   23534,\n",
              "   25964,\n",
              "   728],\n",
              "  [0, 2, 9, 10, 9, 10, 14, 15, 14, 15, 19, 20, 5, 8, 22, 29, 29, 11],\n",
              "  [1.0,\n",
              "   1.0,\n",
              "   0.5,\n",
              "   0.5,\n",
              "   0.5,\n",
              "   0.5,\n",
              "   0.5,\n",
              "   0.5,\n",
              "   0.5,\n",
              "   0.5,\n",
              "   0.5,\n",
              "   0.5,\n",
              "   1.0,\n",
              "   1.0,\n",
              "   1.0,\n",
              "   1.0,\n",
              "   1.0,\n",
              "   1.0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejwwDE-5bb-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_documents = documents\n",
        "test_doc_entity_index = doc_entity_index\n",
        "test_all_doc_text = all_doc_texts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-N7LgdGq8ES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}