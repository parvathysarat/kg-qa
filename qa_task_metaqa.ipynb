{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "qa_task_metaqa.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMwgTzx5EtmGa/Ck2hYJbgY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parvathysarat/kg-qa/blob/master/qa_task_metaqa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCRC0sIwYVHZ",
        "colab_type": "text"
      },
      "source": [
        "Size of our transG embeddings : 50 (both entities and relations)\n",
        "\n",
        "(contains : \n",
        "- utility functions to get entities, relations, documents from MetaQA processed files\n",
        "- training functions\n",
        "- embedding functions\n",
        "- main\n",
        "<br> Needs to be split into util, training and main files. Also need to add config file with specifications)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzRsTFNQh-DV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "import os\n",
        "import time, datetime\n",
        "import sys\n",
        "import json\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYox1XsCTpyK",
        "colab_type": "code",
        "outputId": "a79eaa16-68b3-448e-f6cc-0aeaa94cd4ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "!git clone https://github.com/parvathysarat/kg-qa\n",
        "# ./kg-qa/data/transg/ has the embeddings obtained by TransG for MetaQA dataset"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'kg-qa'...\n",
            "remote: Enumerating objects: 46, done.\u001b[K\n",
            "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
            "remote: Compressing objects: 100% (42/42), done.\u001b[K\n",
            "remote: Total 46 (delta 16), reused 16 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (46/46), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZqYMyp9W5jp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('./kg-qa/data/transg/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRVc0yyLgA7O",
        "colab_type": "text"
      },
      "source": [
        "### Loading MetaQA datasets - entities, relations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpBbREXgX8PZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import shutil\n",
        "for file in glob.glob('./kg-qa/data/*.txt'):\n",
        "  shutil.move(file,'./kg-qa/data/transg/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m4GwmKLsASk",
        "colab_type": "code",
        "outputId": "dd0f27fe-7157-4491-f2aa-a3d369f90dac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# entities.txt from MetaQa : list of entities\n",
        "\n",
        "def get_entities_relns():\n",
        "  with open('../MetaQA/entities.txt') as f:\n",
        "    entities = {id:line.strip() for id,line in enumerate(f)}\n",
        "    print(len(entities),entities[0])\n",
        "  with open('../MetaQA/relations.txt') as f:\n",
        "    relations = {id:line.strip() for id,line in enumerate(f)}\n",
        "    print(len(relations),relations[0])\n",
        "    return entities, relations    \n",
        "  \n",
        "entities, relations = get_entities_relns()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "43234 Kismet\n",
            "9 has_imdb_rating\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYsP6TcKgHlg",
        "colab_type": "text"
      },
      "source": [
        "### Loading pretrained entity weights (transG) for MetaQA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAp61DouYBYK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# entity.txt storing TransG embeddings of MetaQA\n",
        "\n",
        "def get_num_entity(param='num'):\n",
        "   with open('entity.txt') as f:\n",
        "    if param=='num':\n",
        "      return sum([1 for line in f])\n",
        "    if param=='weights':\n",
        "      arr = []\n",
        "      weights_dict = {}\n",
        "      ct=0\n",
        "      for line in f:\n",
        "        entity = entities[ct]\n",
        "        ct+=1\n",
        "        for idx,el in enumerate(line.split()):\n",
        "          # numeric entities are not vectorized\n",
        "          if el.isnumeric() and idx==0: \n",
        "            continue\n",
        "\n",
        "          if (' '.join(line.split()[:idx]))==entity:\n",
        "            arr.append(np.array(line.split()[idx:],dtype=np.float32))\n",
        "            weights_dict[entity] = np.array(line.split()[idx:],dtype=np.float32)\n",
        "            break\n",
        "      print(len(weights_dict),ct)\n",
        "    pretrained_weights = torch.FloatTensor(arr)  \n",
        "    return weights_dict, pretrained_weights\n",
        "num_entities = get_num_entity()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8sFJIZ5gQAU",
        "colab_type": "code",
        "outputId": "4e9bc67b-661b-4799-8777-55d23c364733",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "num_entities = get_num_entity()\n",
        "entity_weights_dict, pretrained_entity_weights = get_num_entity('weights')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "43233 43234\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNbDy-XYgPfP",
        "colab_type": "text"
      },
      "source": [
        "###Store pretrained weights to embedding vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Opl7WYWljrIJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_embeddings(pretrained_weights):\n",
        "  embeddings = nn.Embedding.from_pretrained(pretrained_weights)  \n",
        "  # entity_embeddings = nn.Embedding(num_embeddings=num_entities+1, embedding_dim=50,padding_idx=num_entities)\n",
        "  # entity_embeddings.weight = nn.Parameter(get_num_entity('weights'))\n",
        "  embeddings.weight.requires_grad = False  \n",
        "  return embeddings\n",
        "entity_embeddings = initialize_embeddings(pretrained_entity_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r83DPFNQyl1h",
        "colab_type": "code",
        "outputId": "a8f0a32b-4a3b-46e5-bc86-87e142368a6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "entity_embeddings"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(43233, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fNDG3FXggkK",
        "colab_type": "text"
      },
      "source": [
        "### Loading pretrained relation weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llPzkMmuzRib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to return the cluster number for each relation\n",
        "# (n_cluster # of embeddings for each relation from TransG based on GMM)\n",
        "\n",
        "def get_relations_clust():\n",
        "  relations_cluster = {}\n",
        "  with open('weight.txt') as f:\n",
        "    for line in f:\n",
        "      relations_cluster[line.split()[0]] = np.argmax(np.array(line.split()[1:], dtype = np.float32))\n",
        "  return relations_cluster\n",
        "rel_clusters = get_relations_clust()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkXFDoFsg2jm",
        "colab_type": "text"
      },
      "source": [
        "(transG uses GMM model hence relations have a mixture of embedding vectors to represent multiple semantic relations, weights of each mixture/cluster stored in weights.txt, loaded into rel_clusters. Here we have used num_clusters=4)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mo4VAGAZDYi8",
        "colab_type": "code",
        "outputId": "460e59b9-b39b-4c2b-84f7-e7a77457ffac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "rel_clusters"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'directed_by': 2,\n",
              " 'has_genre': 3,\n",
              " 'has_imdb_rating': 3,\n",
              " 'has_imdb_votes': 3,\n",
              " 'has_tags': 3,\n",
              " 'in_language': 2,\n",
              " 'release_year': 3,\n",
              " 'starred_actors': 2,\n",
              " 'written_by': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptgBoI6_Dma1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_rel_embeddings(relation):\n",
        "  with open('relation_'+relation+'.txt') as f:\n",
        "    for line in f:\n",
        "      if int(line[0])==rel_clusters[relation]:\n",
        "        return np.array(line.split()[1:],dtype=np.float32)\n",
        "\n",
        "rel_weights_dict= {}\n",
        "pretrained_relation_weights = []\n",
        "for rel in rel_clusters:\n",
        "  rel_weights_dict[rel] = get_rel_embeddings(rel)\n",
        "  pretrained_relation_weights.append(rel_weights_dict[rel])\n",
        "pretrained_relation_weights = torch.FloatTensor(pretrained_relation_weights)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCuKACBJI5rY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "relation_embeddings = initialize_embeddings(pretrained_relation_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GeKANMVJGIX",
        "colab_type": "code",
        "outputId": "38bbfb54-eff7-423a-9918-fee470c98f88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(entity_embeddings,relation_embeddings)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Embedding(43233, 50) Embedding(9, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISXlyIFAllLb",
        "colab_type": "text"
      },
      "source": [
        "Mapping vocabulary, entities and relations to ids. \n",
        "dicts of {value:id} format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFFydLsjKW2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def map_ids(file):\n",
        "  id_map = {}\n",
        "  with open('../MetaQA/'+file+'.txt') as f:\n",
        "    for line in f:\n",
        "      id_map[line.strip()] = len(id_map)\n",
        "  return id_map\n",
        "\n",
        "vocab_ids = map_ids('vocab')\n",
        "relation_ids = map_ids('relations')\n",
        "entitiy_ids = map_ids('entities')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_04dxdk5iI-W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 874
        },
        "outputId": "9e6f64bb-1c78-485e-df94-b29991d2af10"
      },
      "source": [
        "from pprint import pprint\n",
        "import tqdm\n",
        "def map_documents(file):\n",
        "  documents = {}\n",
        "  with open(file,encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "      \n",
        "      line = json.loads(line)\n",
        "      documents[line['documentId']] = document['document']['text'] \n",
        "      if 'title' in line:\n",
        "        documents[line['documentId']] += \" / \" + document['title']['text']\n",
        "\n",
        "      break\n",
        "\n",
        "map_documents('../MetaQA/documents.json')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'document': {'entities': [{'end': 6,\n",
            "                            'kb_id': 1721,\n",
            "                            'start': 4,\n",
            "                            'text': 'romantic comedy'},\n",
            "                           {'end': 6,\n",
            "                            'kb_id': 4958,\n",
            "                            'start': 4,\n",
            "                            'text': 'Romantic Comedy'},\n",
            "                           {'end': 11,\n",
            "                            'kb_id': 12463,\n",
            "                            'start': 9,\n",
            "                            'text': 'john turturro'},\n",
            "                           {'end': 11,\n",
            "                            'kb_id': 15468,\n",
            "                            'start': 9,\n",
            "                            'text': 'John Turturro'},\n",
            "                           {'end': 16,\n",
            "                            'kb_id': 27467,\n",
            "                            'start': 14,\n",
            "                            'text': 'Brandon Cole'},\n",
            "                           {'end': 1,\n",
            "                            'kb_id': 27466,\n",
            "                            'start': 0,\n",
            "                            'text': 'Illuminata'},\n",
            "                           {'end': 4, 'kb_id': 287, 'start': 3, 'text': '1998'},\n",
            "                           {'end': 18,\n",
            "                            'kb_id': 29534,\n",
            "                            'start': 17,\n",
            "                            'text': 'john'},\n",
            "                           {'end': 25,\n",
            "                            'kb_id': 23534,\n",
            "                            'start': 24,\n",
            "                            'text': 'play'},\n",
            "                           {'end': 25,\n",
            "                            'kb_id': 25964,\n",
            "                            'start': 24,\n",
            "                            'text': 'Play'},\n",
            "                           {'end': 7,\n",
            "                            'kb_id': 728,\n",
            "                            'start': 6,\n",
            "                            'text': 'film'}],\n",
            "              'text': 'illuminata is a 1998 romantic comedy film directed by '\n",
            "                      'john turturro and written by brandon cole and john '\n",
            "                      \"turturro , based on cole 's play .\"},\n",
            " 'documentId': 0,\n",
            " 'title': {'entities': [{'end': 1,\n",
            "                         'kb_id': 27466,\n",
            "                         'start': 0,\n",
            "                         'text': 'Illuminata'},\n",
            "                        {'end': 3, 'kb_id': 728, 'start': 2, 'text': 'film'}],\n",
            "           'text': 'illuminata ( film )'}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXwPe4Ca-55W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "?tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSu8Eb3gCs1O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}